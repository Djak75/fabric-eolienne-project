# ğŸ¥‰ Bronze Layer - Ingestion des donnÃ©es brutes

## ğŸ“‹ Objectif

Cette couche est responsable de l'**ingestion des donnÃ©es brutes** depuis la source (GitHub) vers le Lakehouse Bronze. Les donnÃ©es sont stockÃ©es au format **Delta Lake** sans transformation.

## ğŸ“‚ Notebooks

### `ingestion_bronze.ipynb`
**Objectif** : Charger les fichiers CSV depuis GitHub vers la table Bronze

**FonctionnalitÃ©s** :
- âœ… Lecture des fichiers CSV depuis l'URL GitHub
- âœ… Ingestion incrÃ©mentale (ne pas recharger les donnÃ©es dÃ©jÃ  prÃ©sentes)
- âœ… Ã‰criture au format Delta Lake
- âœ… Gestion des erreurs

**Colonnes chargÃ©es** :
- `datetime` : Date et heure de production
- `turbine_name` : Nom de la turbine
- `latitude`, `longitude` : CoordonnÃ©es GPS
- `region`, `department` : Localisation administrative
- `wind_speed`, `wind_direction` : Conditions de vent
- `energy_kwh` : Production d'Ã©nergie
- `operational_status` : Statut de la turbine

## ğŸ”„ Logique d'ingestion

```python
# Pseudo-code
1. Lire le CSV depuis GitHub
2. VÃ©rifier si des donnÃ©es existent dÃ©jÃ  dans Bronze
3. Si oui : charger uniquement les nouvelles lignes (delta)
4. Si non : charger toutes les donnÃ©es (initial load)
5. Ã‰crire dans la table Bronze au format Delta
```

## ğŸ“Š Table Bronze

**Nom** : `bronze_eolienne_production`

**Format** : Delta Lake

**Mode d'Ã©criture** : `append` (ajout incrÃ©mental)

**ParticularitÃ©s** :
- Aucune transformation appliquÃ©e
- Conservation du format et structure d'origine
- DonnÃ©es brutes telles quelles

## ğŸš€ ExÃ©cution

Ce notebook sera exÃ©cutÃ© par la **Data Pipeline** en premiÃ¨re Ã©tape.

## âš ï¸ Points d'attention

- VÃ©rifier la connectivitÃ© Ã  GitHub
- GÃ©rer les timeouts potentiels
- VÃ©rifier les duplicatas
- Logger les erreurs d'ingestion

---

**Prochaine Ã©tape** : [Silver Layer](../silver/README.md)
